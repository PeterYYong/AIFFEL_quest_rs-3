{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0bbf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90bed4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a5e987",
   "metadata": {},
   "source": [
    "## 데이터 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72741359",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'stanford_dogs',\n",
    "    split=['train', 'test'],\n",
    "    as_supervised=True,\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8177d6",
   "metadata": {},
   "source": [
    "## 주요 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8eea7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_resize_img(image, label):\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return tf.cast(image, tf.float32) / 255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "946f4f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(image, label):\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5963245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for mixup\n",
    "def mixup_2_images(image_a, image_b, label_a, label_b):\n",
    "    ratio = tf.random.uniform([], 0, 1)\n",
    "    \n",
    "    if len(label_a.shape)==0:\n",
    "        label_a = tf.one_hot(label_a, num_classes)\n",
    "    if len(label_b.shape)==0:\n",
    "        label_b = tf.one_hot(label_b, num_classes)\n",
    "    mixed_image= (1-ratio)*image_a + ratio*image_b\n",
    "    mixed_label = (1-ratio)*label_a + ratio*label_b\n",
    "    \n",
    "    return mixed_image, mixed_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b74d00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(image, label, prob=1.0, batch_size=16, img_size=224, num_classes=120):\n",
    "    mixed_imgs = []\n",
    "    mixed_labels = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        image_a = image[i]\n",
    "        label_a = label[i]\n",
    "        j = tf.cast(tf.random.uniform([],0,batch_size), tf.int32)\n",
    "        image_b = image[j]\n",
    "        label_b = label[j]\n",
    "        mixed_img, mixed_label = mixup_2_images(image_a, image_b, label_a, label_b)\n",
    "        mixed_imgs.append(mixed_img)\n",
    "        mixed_labels.append(mixed_label)\n",
    "\n",
    "    mixed_imgs = tf.reshape(tf.stack(mixed_imgs), (batch_size, img_size, img_size, 3))\n",
    "    mixed_labels = tf.reshape(tf.stack(mixed_labels), (batch_size, num_classes))\n",
    "    return mixed_imgs, mixed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbedc5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalize_on_dataset(ds, is_test=False, batch_size=16, with_mixup=False):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img,\n",
    "        num_parallel_calls=2\n",
    "    )\n",
    "    ds = ds.map(\n",
    "        onehot,\n",
    "        num_parallel_calls=2\n",
    "    )\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test and with_mixup:\n",
    "        ds_mixup = ds.map(\n",
    "            mixup,\n",
    "            num_parallel_calls=2\n",
    "        )\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44381a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_conv(history):\n",
    "    \n",
    "    return_history = {'loss' : list(history['loss'].values()),\n",
    "                      'accuracy' : list(history['accuracy'].values()),\n",
    "                      'val_loss' : list(history['val_loss'].values()),\n",
    "                      'val_accuracy' : list(history['val_accuracy'].values())}\n",
    "    \n",
    "    return return_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa40362",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "152ce790",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "427108cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = ds_info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c6d8760",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = apply_normalize_on_dataset(ds_train, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60129bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_all = apply_normalize_on_dataset(ds_test, batch_size=BATCH_SIZE, is_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f804d4",
   "metadata": {},
   "source": [
    "## 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7861c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    base_model = keras.applications.resnet.ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(224,224,3),\n",
    "        pooling='avg')\n",
    "    \n",
    "    output = base_model.output\n",
    "    \n",
    "    output = keras.layers.Dense(num_classes, activation='softmax', use_bias=False)(output)\n",
    "    model = keras.Model(inputs=base_model.input, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3aed51be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_model = build_model(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6aeb61fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 120)          245760      avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,833,472\n",
      "Trainable params: 23,780,352\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cam_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a49ba73",
   "metadata": {},
   "source": [
    "## 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e63cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9292c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(os.getenv('HOME')+'/aiffel/Deep_Dive(CV)_RS10/9_Class_Activation_Map/history/cam_model_resnet50_best_val_loss.h5', verbose=1, save_best_only=True, mode='min', save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3e14c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "750/750 [==============================] - 201s 198ms/step - loss: 2.2170 - accuracy: 0.4482 - val_loss: 3.1214 - val_accuracy: 0.2442\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.12137, saving model to /aiffel/aiffel/Deep_Dive(CV)_RS10/9_Class_Activation_Map/history/cam_model_resnet50_best_val_loss.h5\n",
      "Epoch 2/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.7998 - accuracy: 0.7776 - val_loss: 1.2510 - val_accuracy: 0.6409\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.12137 to 1.25103, saving model to /aiffel/aiffel/Deep_Dive(CV)_RS10/9_Class_Activation_Map/history/cam_model_resnet50_best_val_loss.h5\n",
      "Epoch 3/50\n",
      "750/750 [==============================] - 165s 220ms/step - loss: 0.2513 - accuracy: 0.9448 - val_loss: 0.9629 - val_accuracy: 0.7160\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.25103 to 0.96290, saving model to /aiffel/aiffel/Deep_Dive(CV)_RS10/9_Class_Activation_Map/history/cam_model_resnet50_best_val_loss.h5\n",
      "Epoch 4/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0720 - accuracy: 0.9921 - val_loss: 0.8947 - val_accuracy: 0.7441\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.96290 to 0.89469, saving model to /aiffel/aiffel/Deep_Dive(CV)_RS10/9_Class_Activation_Map/history/cam_model_resnet50_best_val_loss.h5\n",
      "Epoch 5/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0272 - accuracy: 0.9989 - val_loss: 0.8874 - val_accuracy: 0.7485\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.89469 to 0.88744, saving model to /aiffel/aiffel/Deep_Dive(CV)_RS10/9_Class_Activation_Map/history/cam_model_resnet50_best_val_loss.h5\n",
      "Epoch 6/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0165 - accuracy: 0.9997 - val_loss: 0.9076 - val_accuracy: 0.7445\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.88744\n",
      "Epoch 7/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0123 - accuracy: 0.9997 - val_loss: 0.9210 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.88744\n",
      "Epoch 8/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.9356 - val_accuracy: 0.7470\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.88744\n",
      "Epoch 10/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.9447 - val_accuracy: 0.7460\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.88744\n",
      "Epoch 11/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0061 - accuracy: 0.9998 - val_loss: 0.9500 - val_accuracy: 0.7428\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.88744\n",
      "Epoch 12/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0054 - accuracy: 0.9999 - val_loss: 0.9573 - val_accuracy: 0.7446\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.88744\n",
      "Epoch 13/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0050 - accuracy: 0.9998 - val_loss: 0.9650 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.88744\n",
      "Epoch 14/50\n",
      "750/750 [==============================] - 165s 220ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.9714 - val_accuracy: 0.7460\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.88744\n",
      "Epoch 15/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9803 - val_accuracy: 0.7456\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.88744\n",
      "Epoch 16/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 1.0037 - val_accuracy: 0.7388\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.88744\n",
      "Epoch 17/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.7431\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.88744\n",
      "Epoch 18/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.9935 - val_accuracy: 0.7456\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.88744\n",
      "Epoch 19/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9986 - val_accuracy: 0.7451\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.88744\n",
      "Epoch 20/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9978 - val_accuracy: 0.7452\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.88744\n",
      "Epoch 21/50\n",
      "750/750 [==============================] - 165s 220ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 1.0110 - val_accuracy: 0.7446\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.88744\n",
      "Epoch 22/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 1.0101 - val_accuracy: 0.7443\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.88744\n",
      "Epoch 23/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0077 - val_accuracy: 0.7458\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.88744\n",
      "Epoch 24/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 1.0132 - val_accuracy: 0.7444\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.88744\n",
      "Epoch 25/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 1.0551 - val_accuracy: 0.7415\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.88744\n",
      "Epoch 26/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 1.0169 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.88744\n",
      "Epoch 27/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0215 - val_accuracy: 0.7452\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.88744\n",
      "Epoch 28/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0225 - val_accuracy: 0.7459\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.88744\n",
      "Epoch 29/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0322 - val_accuracy: 0.7472\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.88744\n",
      "Epoch 30/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 1.0383 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.88744\n",
      "Epoch 31/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0330 - val_accuracy: 0.7421\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.88744\n",
      "Epoch 32/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 1.0343 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.88744\n",
      "Epoch 33/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0293 - val_accuracy: 0.7441\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.88744\n",
      "Epoch 34/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 1.0446 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.88744\n",
      "Epoch 35/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 1.0459 - val_accuracy: 0.7408\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.88744\n",
      "Epoch 36/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 1.0519 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.88744\n",
      "Epoch 37/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0643 - val_accuracy: 0.7394\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.88744\n",
      "Epoch 39/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0474 - val_accuracy: 0.7450\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.88744\n",
      "Epoch 40/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0562 - val_accuracy: 0.7450\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.88744\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 1.0535 - val_accuracy: 0.7444\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.88744\n",
      "Epoch 42/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0551 - val_accuracy: 0.7437\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.88744\n",
      "Epoch 43/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 9.2565e-04 - accuracy: 1.0000 - val_loss: 1.0558 - val_accuracy: 0.7459\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.88744\n",
      "Epoch 44/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 8.8128e-04 - accuracy: 1.0000 - val_loss: 1.0637 - val_accuracy: 0.7437\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.88744\n",
      "Epoch 45/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 9.3268e-04 - accuracy: 1.0000 - val_loss: 1.0631 - val_accuracy: 0.7425\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.88744\n",
      "Epoch 46/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 8.9443e-04 - accuracy: 1.0000 - val_loss: 1.0634 - val_accuracy: 0.7453\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.88744\n",
      "Epoch 47/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 9.1277e-04 - accuracy: 1.0000 - val_loss: 1.0734 - val_accuracy: 0.7450\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.88744\n",
      "Epoch 48/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 8.4317e-04 - accuracy: 1.0000 - val_loss: 1.0683 - val_accuracy: 0.7438\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.88744\n",
      "Epoch 49/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 8.7127e-04 - accuracy: 1.0000 - val_loss: 1.0726 - val_accuracy: 0.7435\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.88744\n",
      "Epoch 50/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 7.9908e-04 - accuracy: 1.0000 - val_loss: 1.0736 - val_accuracy: 0.7430\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.88744\n"
     ]
    }
   ],
   "source": [
    "cam_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_resnet50_cam = cam_model.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/16),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/16),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test_all,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44d413c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_model.save_weights(os.getenv('HOME')+'/aiffel/Deep_Dive(CV)_RS10/9_Class_Activation_Map/history/cam_model_resnet50_last.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcea2bb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "cam_model.save(os.getenv('HOME')+'/aiffel/Deep_Dive(CV)_RS10/9_Class_Activation_Map/history/cam_model_resnet50.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4f34de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history/history_resnet50.json', 'w') as f:\n",
    "    pd.DataFrame(history_resnet50_cam.history).to_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb0b6ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(history_resnet50_cam.history['loss'], 'r')\n",
    "plt.plot(history_resnet50_cam.history['val_loss'], 'b')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history_resnet50_cam.history['accuracy'], 'r')\n",
    "plt.plot(history_resnet50_cam.history['val_accuracy'], 'b')\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
